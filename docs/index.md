# genai-lab

**Generative AI for Computational Biology**: Research into foundation models and generative methods for accelerating drug discovery, understanding treatment responses, and enabling in silico biological experimentation.

## Overview

This project investigates generative modeling approaches across computational biology, inspired by emerging platforms such as:

- **Gene Expression**: [Synthesize Bio](https://www.synthesize.bio/) (GEM-1), [Deep Genomics](https://www.deepgenomics.com/) (BigRNA)
- **DNA Sequence**: [Arc Institute](https://arcinstitute.org/tools/evo) (Evo 2), [InstaDeep](https://www.instadeep.com/) (Nucleotide Transformer)
- **Single-Cell**: [Geneformer](https://huggingface.co/ctheodoris/Geneformer), [scGPT](https://github.com/bowang-lab/scGPT)
- **Gene Editing**: [Profluent](https://www.profluent.bio/) (OpenCRISPR)

**Research Goals:**

1. **Investigate** state-of-the-art generative architectures (VAE, flows, diffusion, transformers) for biological sequences and multi-omics data
2. **Develop** reusable, modular components for conditional generation and counterfactual simulation
3. **Explore** causal inference methods for predicting treatment responses and perturbation effects
4. **Contribute** to the growing field of generative biology with reproducible implementations and benchmarks

See [docs/INDUSTRY_LANDSCAPE.md](docs/INDUSTRY_LANDSCAPE.md) for a comprehensive survey of companies and technologies in this space.

## Project Structure

```text
genai-lab/
â”œâ”€â”€ src/genailab/
â”‚   â”œâ”€â”€ foundation/     # ğŸ†• Foundation model adaptation framework
â”‚   â”‚   â”œâ”€â”€ configs/        # Resource-aware model configs (small/medium/large)
â”‚   â”‚   â”œâ”€â”€ tuning/         # LoRA, adapters, freezing strategies
â”‚   â”‚   â”œâ”€â”€ conditioning/   # FiLM, cross-attention, CFG (planned)
â”‚   â”‚   â””â”€â”€ recipes/        # End-to-end pipelines (planned)
â”‚   â”œâ”€â”€ data/           # Data loading, transforms, preprocessing
â”‚   â”‚   â”œâ”€â”€ paths.py        # Standardized data path management
â”‚   â”‚   â”œâ”€â”€ sc_preprocess.py    # scRNA-seq preprocessing (Scanpy)
â”‚   â”‚   â””â”€â”€ bulk_preprocess.py  # Bulk RNA-seq preprocessing
â”‚   â”œâ”€â”€ model/          # Encoders, decoders, VAE, diffusion architectures
â”‚   â”‚   â”œâ”€â”€ vae.py          # CVAE, CVAE_NB, CVAE_ZINB
â”‚   â”‚   â”œâ”€â”€ encoders.py     # ConditionEncoder, etc.
â”‚   â”‚   â”œâ”€â”€ decoders.py     # Gaussian, NB, ZINB decoders
â”‚   â”‚   â””â”€â”€ diffusion/      # Diffusion models (DDPM, score networks)
â”‚   â”œâ”€â”€ objectives/     # Loss functions, regularizers
â”‚   â”‚   â””â”€â”€ losses.py       # ELBO, NB, ZINB losses
â”‚   â”œâ”€â”€ eval/           # Metrics, diagnostics, plotting
â”‚   â”œâ”€â”€ workflows/      # Training, simulation, benchmarking
â”‚   â””â”€â”€ utils/          # Config, reproducibility
â”œâ”€â”€ docs/               # Theory documents and derivations
â”‚   â”œâ”€â”€ foundation_models/  # ğŸ†• Foundation model adaptation
â”‚   â”œâ”€â”€ DiT/            # ğŸ†• Diffusion Transformers
â”‚   â”œâ”€â”€ JEPA/           # ğŸ†• Joint Embedding Predictive Architecture
â”‚   â”œâ”€â”€ latent_diffusion/   # ğŸ†• Latent diffusion for biology
â”‚   â”œâ”€â”€ DDPM/           # Denoising Diffusion Probabilistic Models
â”‚   â”œâ”€â”€ VAE/            # VAE theory and derivations
â”‚   â”œâ”€â”€ EBM/            # Energy-based models
â”‚   â”œâ”€â”€ score_matching/ # Score matching and energy functions
â”‚   â”œâ”€â”€ flow_matching/  # Flow matching & rectified flow
â”‚   â””â”€â”€ datasets/       # Data preparation guides
â”œâ”€â”€ notebooks/          # Educational tutorials (interactive learning)
â”‚   â”œâ”€â”€ foundation_models/  # ğŸ†• Foundation adaptation tutorials
â”‚   â”œâ”€â”€ diffusion/      # Diffusion models tutorials
â”‚   â”œâ”€â”€ vae/            # VAE tutorials
â”‚   â””â”€â”€ foundations/    # Mathematical foundations
â”œâ”€â”€ examples/           # Production scripts (real-world applications)
â”‚   â”œâ”€â”€ perturbation/   # Drug response, perturbation prediction
â”‚   â””â”€â”€ utils/          # Helper modules for examples
â”œâ”€â”€ scripts/            # Training scripts with CLI
â”‚   â””â”€â”€ diffusion/      # Diffusion model training scripts
â”œâ”€â”€ data/               # Local data storage (gitignored)
â”œâ”€â”€ tests/
â””â”€â”€ environment.yml     # Conda environment specification
```

## Documentation & Learning Resources

### Theory Documents (`docs/`)

Detailed theory, derivations, and mathematical foundations:

| Topic | Description | Start Here |
|-------|-------------|------------|
| ğŸ†• [foundation_models](docs/foundation_models/) | Foundation model adaptation (LoRA, adapters, freezing) | [leveraging_foundation_models_v2.md](docs/foundation_models/leveraging_foundation_models_v2.md) |
| ğŸ†• [DiT](docs/DiT/) | Diffusion Transformers (architecture, training, sampling) | [README.md](docs/DiT/README.md) |
| ğŸ†• [JEPA](docs/JEPA/) | Joint Embedding Predictive Architecture | [README.md](docs/JEPA/README.md) |
| ğŸ†• [latent_diffusion](docs/latent_diffusion/) | Latent diffusion with NB/ZINB decoders | [README.md](docs/latent_diffusion/README.md) |
| [DDPM](docs/DDPM/) | Denoising Diffusion Probabilistic Models | [README.md](docs/DDPM/README.md) |
| [VAE](docs/VAE/) | Variational Autoencoders (ELBO, inference, training) | [VAE-01-overview.md](docs/VAE/VAE-01-overview.md) |
| [beta-VAE](docs/beta-VAE/) | VAE with disentanglement (Î² parameter) | [beta_vae.md](docs/beta-VAE/beta_vae.md) |
| [EBM](docs/EBM/) | Energy-Based Models (Boltzmann, partition functions) | [README.md](docs/EBM/README.md) |
| [score_matching](docs/score_matching/) | Score functions, Fisher vs Stein scores | [README.md](docs/score_matching/README.md) |
| [flow_matching](docs/flow_matching/) | Flow matching & rectified flow | [README.md](docs/flow_matching/README.md) |
| [datasets](docs/datasets/) | Datasets & preprocessing pipelines | [README.md](docs/datasets/README.md) |
| [incubation](docs/incubation/) | Ideas under development | [README.md](docs/incubation/README.md) |

### Ideas Under Incubation (`docs/incubation/`)

Exploratory architectural proposals and application ideas not yet implemented:

| Document | Focus |
|----------|-------|
| [joint_latent_space_and_JEPA.md](docs/incubation/joint_latent_space_and_JEPA.md) | Joint latent spaces for static/dynamic data, JEPA for Perturb-seq |
| [generative-ai-for-gene-expression-prediction.md](docs/incubation/generative-ai-for-gene-expression-prediction.md) | Diffusion/VAE/Flow for gene expression with uncertainty |
| [generative-ai-for-perturbation-modeling.md](docs/incubation/generative-ai-for-perturbation-modeling.md) | Generative approaches for scPerturb, beyond GEM-1 |

**Key insights from incubation:**

- **Joint latent spaces**: Static (bulk RNA-seq) and dynamic (Perturb-seq) data can share the same manifold
- **JEPA over reconstruction**: Predicting embeddings is more robust for biology
- **Hybrid predictive-generative**: Combine GEM-1-style predictors with generative wrappers for uncertainty

### Interactive Tutorials (`notebooks/`)

Educational Jupyter notebooks for hands-on learning:

| Topic | Description | Start Here |
|-------|-------------|------------|
| ğŸ†• [foundation_models](notebooks/foundation_models/) | Foundation model adaptation (LoRA, adapters, resource management) | [README.md](notebooks/foundation_models/README.md) |
| [diffusion](notebooks/diffusion/) | Diffusion models (DDPM, score-based, flow matching) | [01_ddpm_basics.ipynb](notebooks/diffusion/01_ddpm_basics.ipynb) |
| [vae](notebooks/vae/) | VAE tutorials (coming soon) | - |
| [foundations](notebooks/foundations/) | Mathematical foundations (coming soon) | - |

See [notebooks/README.md](notebooks/README.md) for learning paths and progression.

### Production Examples (`examples/`)

Ready-to-use Python scripts for real-world applications:

- `01_bulk_cvae.ipynb` â€” Train CVAE on bulk RNA-seq
- `02_pbmc3k_cvae_nb.ipynb` â€” Train CVAE with NB decoder on scRNA-seq
- `perturbation/` â€” Drug response and perturbation prediction (coming soon)

**How to use:**

- **Learning**: Start with `notebooks/` for interactive tutorials
- **Theory**: Reference `docs/` for detailed derivations
- **Application**: Use `examples/` for production workflows
- Follow the [ROADMAP](docs/ROADMAP.md) for structured progression

## Installation

### Using mamba + poetry (recommended)

```bash
# Create conda environment
mamba create -n genailab python=3.11 -y
mamba activate genailab

# Install poetry if not available
pip install poetry

# Install package in editable mode
poetry install

# Optional: install bio dependencies (scanpy, anndata)
poetry install --with bio

# Optional: install dev dependencies
poetry install --with dev
```

### Quick start

```bash
# Verify installation
python -c "import genailab; print(genailab.__version__)"

# Run toy training (once implemented)
genailab-train --config configs/cvae_toy.yaml
```

## Milestones

### Stage 1: Variational Autoencoders âœ…

- [x] Core CVAE implementation with condition encoding
- [x] Gaussian decoder (MSE reconstruction)
- [x] Negative Binomial decoder for count data (`CVAE_NB`)
- [x] Zero-Inflated Negative Binomial decoder (`CVAE_ZINB`)
- [x] ELBO loss with KL annealing support
- [x] Comprehensive documentation (VAE-01 through VAE-09)
- [x] Unit tests for all model variants

### Stage 2: Data Pipeline âœ…

- [x] Standardized data path management (`genailab.data.paths`)
- [x] scRNA-seq preprocessing with Scanpy
- [x] Bulk RNA-seq preprocessing (Python + R/recount3)
- [x] Environment setup (conda/mamba + Poetry)
- [x] Data preparation documentation

### Stage 3: Score Matching & Energy Functions âœ…

- [x] Score matching overview documentation
- [x] Energy functions deep dive (Boltzmann, partition function)
- [x] VP-SDE and VE-SDE formulations
- [x] Denoising score matching loss

### Stage 4: Diffusion Models âœ…

- [x] Forward/reverse diffusion process (VP-SDE, VE-SDE)
- [x] Score networks (MLP, TabularScoreNetwork, UNet2D, UNet3D)
- [x] Medical imaging diffusion (synthetic X-rays)
- [x] Training scripts with configurable model sizes
- [x] RunPod setup documentation for GPU training
- [x] Comprehensive DDPM documentation series
- [x] Gene expression architectures (latent tokens, pathway tokens)
- [ ] Conditional generation with classifier-free guidance
- [ ] Flow matching implementation

### Stage 5: Foundation Model Adaptation âœ…

- [x] Resource-aware model configurations (small/medium/large)
- [x] Auto-detection of hardware (M1 Mac, RunPod, Cloud)
- [x] LoRA (Low-Rank Adaptation) implementation
- [x] Comprehensive documentation (DiT, JEPA, Latent Diffusion)
- [ ] Adapters and freezing strategies
- [ ] Conditioning modules (FiLM, cross-attention, CFG)
- [ ] Tutorial notebooks for each adaptation pattern
- [ ] End-to-end recipes for gene expression tasks

### Stage 6: Advanced Architectures ğŸ“

- [x] DiT (Diffusion Transformers) documentation
- [x] JEPA (Joint Embedding Predictive Architecture) documentation
- [x] Latent Diffusion documentation
- [ ] DiT implementation for gene expression
- [ ] JEPA implementation for Perturb-seq
- [ ] Flow matching implementation

### Stage 7: Counterfactual & Causal (Planned)

- [ ] Counterfactual generation pipeline
- [ ] Deconfounding / SCM-flavored latent model
- [ ] Causal regularization via invariance

## Industry Landscape

Companies and platforms pioneering generative AI for drug discovery and biological research:

### Gene Expression & Multi-Omics Foundation Models

| Company | Focus | Key Technology |
|---------|-------|----------------|
| [Synthesize Bio](https://www.synthesize.bio/) | Gene expression generation | GEM-1 foundation model |
| [Ochre Bio](https://www.ochre-bio.com/) | Liver disease, RNA therapeutics | Functional genomics + AI |
| [Deep Genomics](https://www.deepgenomics.com/) | RNA biology & therapeutics | BigRNA (~2B params) |
| [Helical](https://www.helical.ai/) | DNA/RNA foundation models | Helix-mRNA, open-source platform |
| [Noetik](https://www.noetik.ai/) | Cancer biology | OCTO model for treatment prediction |

### Protein & Structure-Based Discovery

| Company | Focus | Key Technology |
|---------|-------|----------------|
| [Isomorphic Labs](https://www.isomorphiclabs.com/) | Drug discovery (DeepMind spin-off) | AlphaFold 3 |
| [EvolutionaryScale](https://www.evolutionaryscale.ai/) | Protein design | ESM3 generative model |
| [Generate:Biomedicines](https://generatebiomedicines.com/) | Protein therapeutics | Generative Biologyâ„¢ platform |
| [Chai Discovery](https://www.chaidiscovery.com/) | Molecular structure | Chai-1/2 (antibody design) |
| [Recursion](https://www.recursion.com/) | Phenomics + drug discovery | Phenom-Beta, BioHive-2 |

### Clinical & Treatment Response

| Company | Focus | Key Technology |
|---------|-------|----------------|
| [Insilico Medicine](https://insilico.com/) | End-to-end drug discovery | Pharma.AI, Precious3GPT |
| [Tempus](https://www.tempus.com/) | Precision medicine | AI-driven clinical insights |
| [Owkin](https://www.owkin.com/) | Clinical trials, pathology | Federated learning |
| [Retro Biosciences](https://www.retro.bio/) | Cellular reprogramming | GPT-4b micro (with OpenAI) |

### Other Notable Players

- **BioMap** â€” xTrimo (210B params, multi-modal)
- **Ginkgo Bioworks** â€” Synthetic biology + Google Cloud partnership
- **Bioptimus** â€” H-Optimus-0 pathology foundation model
- **Atomic AI** â€” RNA structure (ATOM-1, PARSE platform)
- **Enveda Biosciences** â€” PRISM for small molecule discovery

## References

### Academic

- [Geneformer](https://www.nature.com/articles/s41586-023-06139-9) â€” Transfer learning for single-cell biology
- [scVI](https://www.nature.com/articles/s41592-018-0229-2) â€” Probabilistic modeling of scRNA-seq
- [CPA](https://www.embopress.org/doi/full/10.15252/msb.202211517) â€” Compositional Perturbation Autoencoder

### Industry

- [Synthesize Bio Blog](https://www.synthesize.bio/blog)
- [17 Companies Pioneering AI Foundation Models in Pharma](https://www.biopharmatrend.com/business-intelligence/14-companies-pioneering-ai-foundation-models-in-pharma-and-biotech/)
- [NVIDIA BioNeMo Platform](https://blogs.nvidia.com/blog/drug-discovery-bionemo-generative-ai/)

## Related Projects

### [causal-bio-lab](../causal-bio-lab/) â€” Causal AI/ML for Computational Biology

**Complementary Focus:** While `genai-lab` focuses on **modeling data-generating processes** through generative models, `causal-bio-lab` focuses on **uncovering causal structures** and **estimating causal effects** from observational and interventional data.

**Synergy:**

- **Generative models** (VAE, diffusion) can learn rich representations but may capture spurious correlations
- **Causal methods** (probabilistic graphical models, causal discovery, structural equations) ensure models capture true mechanisms, not just statistical patterns
- **Together:** Causal generative models combine the best of both worldsâ€”realistic simulation with causal guarantees

**Key Integration Points:**

1. **Causal representation learning:** Learn disentangled latent spaces that respect causal structure (causal VAEs, identifiable VAEs)
2. **Causal discovery for architecture:** Use learned causal graphs to constrain generative model structure
3. **Counterfactual validation:** Use causal inference methods (do-calculus, structural equations) to validate generated predictions
4. **Causal regularization:** Apply invariance principles and interventional consistency losses for better generalization

**Example Workflow:**

```text
1. Train a CVAE on gene expression data (genai-lab)
2. Discover causal gene regulatory network (causal-bio-lab)
3. Constrain VAE latent space to respect causal structure
4. Generate counterfactual perturbation responses with causal guarantees
5. Estimate treatment effects using both generative and causal methods
```

**Why This Matters for Computational Biology:**

- **Drug discovery:** Generate realistic molecular perturbations while ensuring causal mechanisms are preserved
- **Treatment response:** Predict individual-level effects (counterfactuals) with uncertainty quantification
- **Target identification:** Discover causal drivers, not just biomarkers
- **Combination therapy:** Model synergistic effects through causal interaction terms

See `causal-bio-lab` Milestone 0.5 (SCMs) and Milestone D (Causal Representation Learning) for integration work.

## License

MIT
