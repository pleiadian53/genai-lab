{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Models for Medical Imaging\n",
    "\n",
    "This notebook applies diffusion models to **realistic medical images**, demonstrating practical applications of the SDE framework.\n",
    "\n",
    "**Use case**: Generate synthetic chest X-rays for data augmentation and medical AI training.\n",
    "\n",
    "**Learning objectives:**\n",
    "1. Apply U-Net architecture to real medical images\n",
    "2. Handle grayscale medical imaging data preprocessing\n",
    "3. Train diffusion models on 128×128 X-ray images\n",
    "4. Generate synthetic medical images\n",
    "5. Evaluate with domain-specific metrics\n",
    "\n",
    "**Dataset**: Chest X-ray images (downsampled to 128×128 for computational efficiency)\n",
    "\n",
    "**Prerequisites**: `02_sde_formulation.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path('../../../src').resolve()))\n",
    "\n",
    "from genailab.diffusion import (\n",
    "    VPSDE,\n",
    "    UNet2D,\n",
    "    train_score_network,\n",
    "    sample_reverse_sde,\n",
    "    sample_probability_flow_ode\n",
    ")\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "\n",
    "# Random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation\n",
    "\n",
    "We'll use chest X-ray images. You have several options:\n",
    "\n",
    "### Option A: Download Real Dataset (Recommended)\n",
    "1. **NIH Chest X-ray Dataset**: Download from [Kaggle](https://www.kaggle.com/nih-chest-xrays/data)\n",
    "2. **COVID-19 Radiography**: Smaller, faster to download\n",
    "3. **MIMIC-CXR**: Requires credentialing but highest quality\n",
    "\n",
    "### Option B: Use Synthetic Medical Images (For Quick Start)\n",
    "Generate synthetic X-ray-like images for testing the pipeline.\n",
    "\n",
    "### Option C: Use Your Pathology Images\n",
    "Adapt this notebook to use histopathology images from your `pathology-ai-lab` project.\n",
    "\n",
    "For this demo, we'll start with **Option B** (synthetic) and show how to adapt to real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticXRayDataset(Dataset):\n",
    "    \"\"\"Synthetic X-ray-like images for testing the pipeline.\n",
    "    \n",
    "    These mimic real X-ray characteristics:\n",
    "    - Grayscale (1 channel)\n",
    "    - Anatomical structures (simulated with Gaussian blobs)\n",
    "    - Noise patterns typical of radiography\n",
    "    \n",
    "    Replace this with real medical images for production use.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_samples=1000, img_size=128, seed=42):\n",
    "        self.n_samples = n_samples\n",
    "        self.img_size = img_size\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # Generate synthetic images\n",
    "        self.images = self._generate_synthetic_xrays()\n",
    "    \n",
    "    def _generate_synthetic_xrays(self):\n",
    "        \"\"\"Generate X-ray-like images with anatomical structures.\"\"\"\n",
    "        images = []\n",
    "        \n",
    "        for _ in range(self.n_samples):\n",
    "            # Start with background\n",
    "            img = np.random.randn(self.img_size, self.img_size) * 0.1 + 0.5\n",
    "            \n",
    "            # Add anatomical structures (simulated with Gaussian blobs)\n",
    "            # Lungs (two large dark regions)\n",
    "            y, x = np.ogrid[:self.img_size, :self.img_size]\n",
    "            \n",
    "            # Left lung\n",
    "            cx1, cy1 = self.img_size // 3, self.img_size // 2\n",
    "            r1 = self.img_size // 4\n",
    "            mask1 = ((x - cx1)**2 + (y - cy1)**2) < r1**2\n",
    "            img[mask1] *= 0.6  # Darker (air-filled)\n",
    "            \n",
    "            # Right lung\n",
    "            cx2, cy2 = 2 * self.img_size // 3, self.img_size // 2\n",
    "            r2 = self.img_size // 4\n",
    "            mask2 = ((x - cx2)**2 + (y - cy2)**2) < r2**2\n",
    "            img[mask2] *= 0.6\n",
    "            \n",
    "            # Heart (bright region in center)\n",
    "            cx3, cy3 = self.img_size // 2, self.img_size // 2\n",
    "            r3 = self.img_size // 8\n",
    "            mask3 = ((x - cx3)**2 + (y - cy3)**2) < r3**2\n",
    "            img[mask3] *= 1.3  # Brighter (dense tissue)\n",
    "            \n",
    "            # Add ribs (horizontal bright lines)\n",
    "            for i in range(5):\n",
    "                rib_y = self.img_size // 4 + i * self.img_size // 10\n",
    "                img[rib_y-1:rib_y+2, :] *= 1.2\n",
    "            \n",
    "            # Clip to [0, 1]\n",
    "            img = np.clip(img, 0, 1)\n",
    "            \n",
    "            images.append(img)\n",
    "        \n",
    "        return np.array(images, dtype=np.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return as (1, H, W) tensor\n",
    "        img = self.images[idx]\n",
    "        img = torch.FloatTensor(img).unsqueeze(0)  # Add channel dimension\n",
    "        # Normalize to [-1, 1] for diffusion models\n",
    "        img = img * 2 - 1\n",
    "        return img\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "dataset = SyntheticXRayDataset(n_samples=2000, img_size=128)\n",
    "print(f\"Dataset: {len(dataset)} images, shape: {dataset[0].shape}\")\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "print(f\"Batches per epoch: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    img = dataset[i].squeeze().numpy()\n",
    "    # Denormalize from [-1, 1] to [0, 1]\n",
    "    img = (img + 1) / 2\n",
    "    axes[i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Sample {i+1}')\n",
    "\n",
    "plt.suptitle('Synthetic Chest X-ray Images (128×128)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: These are synthetic images for demonstration.\")\n",
    "print(\"Replace with real medical images for production use.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Architecture: U-Net for Medical Images\n",
    "\n",
    "We use the **UNet2D** architecture specifically designed for medical imaging:\n",
    "- Encoder-decoder with skip connections\n",
    "- Multi-scale feature extraction\n",
    "- GroupNorm (works well with small batches)\n",
    "- Time conditioning at each resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize U-Net model\n",
    "model = UNet2D(\n",
    "    in_channels=1,              # Grayscale X-rays\n",
    "    out_channels=1,\n",
    "    base_channels=64,           # Start with 64 channels\n",
    "    channel_multipliers=(1, 2, 4, 8),  # 64 → 128 → 256 → 512\n",
    "    num_res_blocks=2,           # 2 residual blocks per resolution\n",
    "    time_emb_dim=256,\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Test forward pass\n",
    "x_test = torch.randn(4, 1, 128, 128).to(device)\n",
    "t_test = torch.rand(4).to(device)\n",
    "out_test = model(x_test, t_test)\n",
    "print(f\"Input shape: {x_test.shape}\")\n",
    "print(f\"Output shape: {out_test.shape}\")\n",
    "print(\"✓ Model initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Setup\n",
    "\n",
    "We'll use:\n",
    "- **VP-SDE** with cosine schedule (better for images)\n",
    "- **Denoising score matching** loss\n",
    "- **Adam optimizer** with learning rate 2e-4\n",
    "- **Gradient clipping** for stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SDE with cosine schedule (recommended for images)\n",
    "sde = VPSDE(schedule='cosine', T=1.0)\n",
    "print(f\"Using {sde.schedule_name} noise schedule\")\n",
    "\n",
    "# Visualize the noise schedule\n",
    "t_vals = np.linspace(0, 1, 100)\n",
    "beta_vals = [sde.beta(t) for t in t_vals]\n",
    "alpha_bar_vals = [sde.schedule.alpha_bar(t) for t in t_vals]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(t_vals, beta_vals)\n",
    "axes[0].set_xlabel('Time t')\n",
    "axes[0].set_ylabel('β(t)')\n",
    "axes[0].set_title('Noise Schedule')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(t_vals, alpha_bar_vals)\n",
    "axes[1].set_xlabel('Time t')\n",
    "axes[1].set_ylabel('ᾱ(t)')\n",
    "axes[1].set_title('Signal Retention')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Forward Diffusion Process\n",
    "\n",
    "Let's see how the SDE corrupts a real X-ray image over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one sample image\n",
    "x0 = dataset[0].unsqueeze(0).numpy()  # (1, 1, 128, 128)\n",
    "\n",
    "# Apply forward diffusion at different times\n",
    "times = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, t in enumerate(times):\n",
    "    if t == 0:\n",
    "        xt = x0\n",
    "    else:\n",
    "        xt, _ = sde.sample_from_marginal(x0, t)\n",
    "    \n",
    "    # Denormalize and display\n",
    "    img = xt[0, 0]  # (128, 128)\n",
    "    img = (img + 1) / 2  # [-1, 1] → [0, 1]\n",
    "    \n",
    "    axes[i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f't = {t:.1f}')\n",
    "    \n",
    "    # Show std\n",
    "    _, std = sde.marginal_prob(x0, t)\n",
    "    axes[i].text(0.05, 0.95, f'σ={std:.3f}', \n",
    "                transform=axes[i].transAxes,\n",
    "                verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.suptitle('Forward Diffusion: X-ray → Noise', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observation: The X-ray structure gradually dissolves into Gaussian noise.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Diffusion Model\n",
    "\n",
    "**Note**: Training on medical images takes longer than toy examples.\n",
    "- **Quick test**: 1,000 epochs (~10 minutes on M1 Mac)\n",
    "- **Good quality**: 10,000 epochs (~1-2 hours)\n",
    "- **High quality**: 50,000+ epochs (~8-12 hours)\n",
    "\n",
    "For this demo, we'll train for a moderate number of epochs. You can increase for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function adapted for image data\n",
    "def train_image_diffusion(\n",
    "    model,\n",
    "    dataloader,\n",
    "    sde,\n",
    "    num_epochs=5000,\n",
    "    lr=2e-4,\n",
    "    device='cuda',\n",
    "    save_every=1000,\n",
    "    checkpoint_dir='./checkpoints'\n",
    "):\n",
    "    \"\"\"Train diffusion model on images.\"\"\"\n",
    "    \n",
    "    Path(checkpoint_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
    "        epoch_losses = []\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            x0 = batch.to(device)\n",
    "            batch_size = x0.shape[0]\n",
    "            \n",
    "            # Sample time uniformly\n",
    "            t = torch.rand(batch_size, device=device) * (sde.T - 1e-3) + 1e-3\n",
    "            \n",
    "            # Compute marginal distribution\n",
    "            mean_np, std_np = sde.marginal_prob(x0.cpu().numpy(), t.cpu().numpy())\n",
    "            mean = torch.FloatTensor(mean_np).to(device)\n",
    "            std = torch.FloatTensor(std_np).to(device)\n",
    "            \n",
    "            # Sample noisy data\n",
    "            noise = torch.randn_like(x0)\n",
    "            xt = mean + std * noise\n",
    "            \n",
    "            # Target score\n",
    "            target_score = -noise / std\n",
    "            \n",
    "            # Predict score\n",
    "            pred_score = model(xt, t)\n",
    "            \n",
    "            # Loss with variance weighting\n",
    "            loss = torch.mean((pred_score - target_score) ** 2 * (std ** 2))\n",
    "            \n",
    "            # Backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_losses.append(loss.item())\n",
    "        \n",
    "        # Log\n",
    "        avg_loss = np.mean(epoch_losses)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 500 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % save_every == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            }, f\"{checkpoint_dir}/checkpoint_epoch_{epoch+1}.pt\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "print(f\"This will take approximately {5000 * len(dataloader) / 60:.0f} minutes on {device}\")\n",
    "\n",
    "losses = train_image_diffusion(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    sde=sde,\n",
    "    num_epochs=5000,  # Increase to 10000-50000 for better quality\n",
    "    lr=2e-4,\n",
    "    device=device,\n",
    "    save_every=1000,\n",
    "    checkpoint_dir='./checkpoints'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curve\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final loss: {losses[-1]:.6f}\")\n",
    "print(f\"Best loss: {min(losses):.6f} at epoch {np.argmin(losses) + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Synthetic X-rays\n",
    "\n",
    "Now let's use the trained model to generate new synthetic X-ray images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling function for images\n",
    "@torch.no_grad()\n",
    "def sample_images(\n",
    "    model,\n",
    "    sde,\n",
    "    n_samples=16,\n",
    "    img_size=128,\n",
    "    num_steps=500,\n",
    "    device='cuda'\n",
    "):\n",
    "    \"\"\"Sample images using reverse SDE.\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Start from noise\n",
    "    x = torch.randn(n_samples, 1, img_size, img_size, device=device)\n",
    "    \n",
    "    dt = -sde.T / num_steps\n",
    "    trajectory = [x.cpu().numpy()]\n",
    "    \n",
    "    for i in tqdm(range(num_steps), desc=\"Sampling\", leave=False):\n",
    "        t = sde.T - i * (-dt)\n",
    "        t_batch = torch.ones(n_samples, device=device) * t\n",
    "        \n",
    "        # Predict score\n",
    "        score = model(x, t_batch)\n",
    "        \n",
    "        # Drift\n",
    "        drift = sde.drift(x.cpu().numpy(), t)\n",
    "        drift = torch.FloatTensor(drift).to(device)\n",
    "        g_t = sde.diffusion(t)\n",
    "        drift = drift - (g_t ** 2) * score\n",
    "        \n",
    "        # Diffusion\n",
    "        noise = torch.randn_like(x)\n",
    "        diffusion = g_t * noise * np.sqrt(-dt)\n",
    "        \n",
    "        # Update\n",
    "        x = x + drift * dt + diffusion\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            trajectory.append(x.cpu().numpy())\n",
    "    \n",
    "    return x.cpu().numpy(), np.array(trajectory)\n",
    "\n",
    "\n",
    "# Generate samples\n",
    "print(\"Generating synthetic X-rays...\")\n",
    "samples, trajectory = sample_images(\n",
    "    model=model,\n",
    "    sde=sde,\n",
    "    n_samples=16,\n",
    "    img_size=128,\n",
    "    num_steps=500,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Generated {samples.shape[0]} images\")\n",
    "print(f\"Trajectory: {len(trajectory)} snapshots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display generated images\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(16):\n",
    "    img = samples[i, 0]  # (128, 128)\n",
    "    # Denormalize from [-1, 1] to [0, 1]\n",
    "    img = (img + 1) / 2\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    axes[i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Generated Synthetic X-rays', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Reverse Diffusion Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show reverse diffusion trajectory\n",
    "num_snapshots = min(6, len(trajectory))\n",
    "indices = np.linspace(0, len(trajectory)-1, num_snapshots, dtype=int)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    xt = trajectory[idx][0, 0]  # First sample, first channel\n",
    "    t_val = sde.T * (1 - idx / (len(trajectory) - 1))\n",
    "    \n",
    "    # Denormalize\n",
    "    img = (xt + 1) / 2\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    axes[i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f't = {t_val:.3f}')\n",
    "\n",
    "plt.suptitle('Reverse Diffusion: Noise → X-ray', fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observation: The model progressively denoises to reveal X-ray structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Real vs Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "\n",
    "# Real images (top row)\n",
    "for i in range(8):\n",
    "    img = dataset[i].squeeze().numpy()\n",
    "    img = (img + 1) / 2\n",
    "    axes[0, i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('Real', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Generated images (bottom row)\n",
    "for i in range(8):\n",
    "    img = samples[i, 0]\n",
    "    img = (img + 1) / 2\n",
    "    img = np.clip(img, 0, 1)\n",
    "    axes[1, i].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('Generated', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Real vs Generated X-rays', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation Metrics\n",
    "\n",
    "For medical images, we evaluate:\n",
    "1. **Visual quality**: Do images look realistic?\n",
    "2. **FID (Fréchet Inception Distance)**: Measures distribution similarity\n",
    "3. **Structural similarity**: SSIM between real and generated\n",
    "4. **Clinical utility**: Can radiologists distinguish real from synthetic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple evaluation: pixel statistics\n",
    "real_images = np.array([dataset[i].squeeze().numpy() for i in range(100)])\n",
    "gen_images = samples[:, 0, :, :]\n",
    "\n",
    "print(\"Pixel Statistics Comparison:\")\n",
    "print(f\"Real - Mean: {real_images.mean():.3f}, Std: {real_images.std():.3f}\")\n",
    "print(f\"Generated - Mean: {gen_images.mean():.3f}, Std: {gen_images.std():.3f}\")\n",
    "\n",
    "# Histogram comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(real_images.flatten(), bins=50, alpha=0.7, label='Real', density=True)\n",
    "axes[0].hist(gen_images.flatten(), bins=50, alpha=0.7, label='Generated', density=True)\n",
    "axes[0].set_xlabel('Pixel Value')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Pixel Value Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Power spectrum (frequency analysis)\n",
    "real_fft = np.abs(np.fft.fft2(real_images[0]))\n",
    "gen_fft = np.abs(np.fft.fft2(gen_images[0]))\n",
    "\n",
    "axes[1].plot(np.log(real_fft[64, :]), label='Real', alpha=0.7)\n",
    "axes[1].plot(np.log(gen_fft[64, :]), label='Generated', alpha=0.7)\n",
    "axes[1].set_xlabel('Frequency')\n",
    "axes[1].set_ylabel('Log Magnitude')\n",
    "axes[1].set_title('Frequency Spectrum (Center Row)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Applications\n",
    "\n",
    "### A. Data Augmentation\n",
    "\n",
    "Use generated images to augment training data for downstream tasks (disease classification, segmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Application: Data Augmentation\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original dataset: {len(dataset)} images\")\n",
    "print(f\"Generated images: {len(samples)} images\")\n",
    "print(f\"Augmented dataset: {len(dataset) + len(samples)} images (+{len(samples)/len(dataset)*100:.0f}%)\")\n",
    "print(\"\\nUse case: Train disease classifier with augmented data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Conditional Generation (Future Work)\n",
    "\n",
    "Extend the model to generate X-rays conditioned on:\n",
    "- Disease labels (normal, pneumonia, COVID-19)\n",
    "- Patient demographics (age, sex)\n",
    "- View angle (PA, lateral)\n",
    "\n",
    "This requires modifying the U-Net to accept condition embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Image-to-Image Translation\n",
    "\n",
    "Use diffusion for:\n",
    "- Super-resolution (low-res → high-res)\n",
    "- Denoising (noisy → clean)\n",
    "- Modality transfer (CT → MRI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "### To improve this notebook:\n",
    "\n",
    "1. **Use real medical images**:\n",
    "   - Download NIH Chest X-ray dataset\n",
    "   - Replace `SyntheticXRayDataset` with real data loader\n",
    "   - Preprocess: resize, normalize, augment\n",
    "\n",
    "2. **Train longer**:\n",
    "   - Increase to 50,000-100,000 epochs\n",
    "   - Use learning rate scheduling\n",
    "   - Implement EMA (exponential moving average)\n",
    "\n",
    "3. **Scale up**:\n",
    "   - Use 256×256 images\n",
    "   - Increase base_channels to 128\n",
    "   - Add attention layers at low resolutions\n",
    "\n",
    "4. **Add conditioning**:\n",
    "   - Condition on disease labels\n",
    "   - Implement classifier-free guidance\n",
    "   - Generate specific pathologies\n",
    "\n",
    "5. **Evaluate rigorously**:\n",
    "   - Compute FID with pretrained features\n",
    "   - Clinical evaluation by radiologists\n",
    "   - Downstream task performance\n",
    "\n",
    "### Connect to your pathology-ai-lab:\n",
    "\n",
    "```python\n",
    "# Adapt this notebook for histopathology\n",
    "from pathology_ai_lab.data import load_camelyon_patches\n",
    "\n",
    "# Load H&E patches\n",
    "patches = load_camelyon_patches(size=96, n_samples=10000)\n",
    "\n",
    "# Train diffusion model on tissue patches\n",
    "model = UNet2D(in_channels=3, out_channels=3, base_channels=64)\n",
    "# ... train ...\n",
    "\n",
    "# Generate synthetic tissue for augmentation\n",
    "synthetic_patches = sample_images(model, sde, n_samples=1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. ✅ Applied U-Net architecture to medical images\n",
    "2. ✅ Trained diffusion model on 128×128 X-rays\n",
    "3. ✅ Generated synthetic medical images\n",
    "4. ✅ Evaluated with pixel statistics and visual inspection\n",
    "5. ✅ Discussed practical applications\n",
    "\n",
    "**Key takeaways**:\n",
    "- U-Net is essential for spatial structure preservation\n",
    "- Medical images require longer training than toy data\n",
    "- Cosine schedule works well for images\n",
    "- Generated images can augment limited medical datasets\n",
    "- Clinical validation is crucial for medical AI\n",
    "\n",
    "**Next**: `04_gene_expression_diffusion.ipynb` - High-dimensional tabular data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
