{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk RNA-seq Conditional VAE\n",
    "\n",
    "This notebook demonstrates training a conditional VAE on bulk RNA-seq data.\n",
    "\n",
    "## Learning Objectives\n",
    "1. Understand the cVAE architecture for gene expression\n",
    "2. Train on synthetic data with tissue/disease/batch conditioning\n",
    "3. Evaluate reconstruction and latent space quality\n",
    "4. Generate counterfactual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from genailab.data.loaders import ToyBulkDataset, split_dataset\n",
    "from genailab.model.conditioning import ConditionSpec, ConditionEncoder\n",
    "from genailab.model.vae import CVAE, elbo_loss\n",
    "from genailab.workflows.train import train_cvae\n",
    "from genailab.eval.counterfactual import counterfactual_decode\n",
    "from genailab.utils.reproducibility import set_seed, get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "set_seed(42)\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Synthetic Dataset\n",
    "\n",
    "We use a toy dataset with:\n",
    "- 5000 samples\n",
    "- 2000 genes\n",
    "- 6 tissues, 3 diseases, 10 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "ds = ToyBulkDataset(\n",
    "    n=5000,\n",
    "    n_genes=2000,\n",
    "    n_tissues=6,\n",
    "    n_diseases=3,\n",
    "    n_batches=10,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Split into train/val\n",
    "train_ds, val_ds = split_dataset(ds, val_frac=0.1)\n",
    "print(f\"Train: {len(train_ds)}, Val: {len(val_ds)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Model\n",
    "\n",
    "The cVAE has:\n",
    "- **Condition Encoder**: Embeds categorical conditions (tissue, disease, batch)\n",
    "- **Encoder**: Maps (x, c) → (μ, σ) for latent z\n",
    "- **Decoder**: Maps (z, c) → x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define condition specification\n",
    "spec = ConditionSpec(\n",
    "    n_cats={\"tissue\": ds.n_tissues, \"disease\": ds.n_diseases, \"batch\": ds.n_batches},\n",
    "    emb_dim=32,\n",
    "    out_dim=128,\n",
    ")\n",
    "\n",
    "# Create model\n",
    "cond_enc = ConditionEncoder(spec)\n",
    "model = CVAE(\n",
    "    n_genes=ds.n_genes,\n",
    "    z_dim=64,\n",
    "    cond_encoder=cond_enc,\n",
    "    hidden=512,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "history = train_cvae(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device=str(device),\n",
    "    epochs=30,\n",
    "    lr=1e-3,\n",
    "    beta=0.5,  # beta-VAE: weight on KL term\n",
    "    outdir=\"runs/cvae_toy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Total Loss')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Total Loss')\n",
    "\n",
    "axes[1].plot(history['train_recon'], label='Train')\n",
    "axes[1].plot(history['val_recon'], label='Val')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Reconstruction Loss')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Reconstruction Loss')\n",
    "\n",
    "axes[2].plot(history['train_kl'], label='Train')\n",
    "axes[2].plot(history['val_kl'], label='Val')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('KL Divergence')\n",
    "axes[2].legend()\n",
    "axes[2].set_title('KL Divergence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of validation data\n",
    "model.eval()\n",
    "batch = next(iter(val_loader))\n",
    "x = batch['x'].to(device)\n",
    "cond = {k: v.to(device) for k, v in batch['cond'].items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(x, cond)\n",
    "    x_hat = out['x_hat']\n",
    "\n",
    "# Plot reconstruction for a few samples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.scatter(x[i].cpu(), x_hat[i].cpu(), alpha=0.3, s=5)\n",
    "    ax.plot([-3, 3], [-3, 3], 'r--', alpha=0.5)\n",
    "    corr = np.corrcoef(x[i].cpu(), x_hat[i].cpu())[0, 1]\n",
    "    ax.set_title(f'Sample {i} (r={corr:.3f})')\n",
    "    ax.set_xlabel('Original')\n",
    "    ax.set_ylabel('Reconstructed')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all validation data\n",
    "all_z = []\n",
    "all_tissue = []\n",
    "all_disease = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        x = batch['x'].to(device)\n",
    "        cond = {k: v.to(device) for k, v in batch['cond'].items()}\n",
    "        mu, _ = model.encode(x, cond)\n",
    "        all_z.append(mu.cpu().numpy())\n",
    "        all_tissue.append(batch['cond']['tissue'].numpy())\n",
    "        all_disease.append(batch['cond']['disease'].numpy())\n",
    "\n",
    "z = np.concatenate(all_z)\n",
    "tissue = np.concatenate(all_tissue)\n",
    "disease = np.concatenate(all_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "z_2d = pca.fit_transform(z)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "scatter1 = axes[0].scatter(z_2d[:, 0], z_2d[:, 1], c=tissue, cmap='tab10', alpha=0.5, s=10)\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "axes[0].set_title('Latent Space (colored by Tissue)')\n",
    "plt.colorbar(scatter1, ax=axes[0])\n",
    "\n",
    "scatter2 = axes[1].scatter(z_2d[:, 0], z_2d[:, 1], c=disease, cmap='tab10', alpha=0.5, s=10)\n",
    "axes[1].set_xlabel('PC1')\n",
    "axes[1].set_ylabel('PC2')\n",
    "axes[1].set_title('Latent Space (colored by Disease)')\n",
    "plt.colorbar(scatter2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Counterfactual Generation\n",
    "\n",
    "The key capability: given a sample with condition c, generate what it would look like under condition c'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get samples with disease=0\n",
    "batch = next(iter(val_loader))\n",
    "mask = batch['cond']['disease'] == 0\n",
    "x = batch['x'][mask][:10].to(device)\n",
    "cond = {k: v[mask][:10].to(device) for k, v in batch['cond'].items()}\n",
    "\n",
    "# Create counterfactual condition: disease 0 -> disease 1\n",
    "cond_cf = {k: v.clone() for k, v in cond.items()}\n",
    "cond_cf['disease'] = torch.ones_like(cond['disease'])\n",
    "\n",
    "# Generate counterfactual\n",
    "with torch.no_grad():\n",
    "    x_cf = counterfactual_decode(model, x, cond, cond_cf)\n",
    "\n",
    "# Analyze changes\n",
    "x_np = x.cpu().numpy()\n",
    "x_cf_np = x_cf.cpu().numpy()\n",
    "mean_change = (x_cf_np - x_np).mean(axis=0)\n",
    "\n",
    "# Plot top changed genes\n",
    "top_idx = np.argsort(np.abs(mean_change))[-20:]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['red' if c > 0 else 'blue' for c in mean_change[top_idx]]\n",
    "plt.barh(range(20), mean_change[top_idx], color=colors, alpha=0.7)\n",
    "plt.yticks(range(20), [f'gene_{i}' for i in top_idx])\n",
    "plt.xlabel('Mean Expression Change')\n",
    "plt.title('Top 20 Genes Affected by Disease 0 → 1 Counterfactual')\n",
    "plt.axvline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. Created a synthetic bulk RNA-seq dataset with tissue/disease/batch effects\n",
    "2. Built and trained a conditional VAE\n",
    "3. Evaluated reconstruction quality\n",
    "4. Visualized the latent space\n",
    "5. Generated counterfactual samples (disease intervention)\n",
    "\n",
    "### Next Steps\n",
    "- Try real data (GEO, TCGA)\n",
    "- Evaluate DE agreement between real and generated contrasts\n",
    "- Add batch adversarial training to reduce batch leakage\n",
    "- Implement scRNA-seq version with Negative Binomial likelihood"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
